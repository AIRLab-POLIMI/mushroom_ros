#!/usr/bin/env python3

import numpy as np

from mushroom_rl_ros.environments import TurtleSim

from mushroom_rl.core import Core
from mushroom_rl.algorithms.policy_search import GPOMDP
from mushroom_rl.approximators.parametric import LinearApproximator
from mushroom_rl.approximators.regressor import Regressor
from mushroom_rl.features.features import Features
from mushroom_rl.features.basis import GaussianRBF
from mushroom_rl.policy import DiagonalGaussianPolicy
from mushroom_rl.utils.optimizers import AdaptiveOptimizer
from mushroom_rl.utils.dataset import compute_J

# Learning parameters
n_epochs = 20
n_iterations = 3
ep_per_run = 10

# Environment
mdp = TurtleSim()

# Policy
n_tilings = 3
n_tiles = [10, 10, 5]
basis = GaussianRBF.generate([10, 10, 5], mdp.info.observation_space.low, mdp.info.observation_space.high)

phi = Features(basis_list=basis)

input_shape = (phi.size,)

approximator_params = dict(input_dim=phi.size)
approximator = Regressor(LinearApproximator, input_shape=input_shape,
                         output_shape=mdp.info.action_space.shape,
                         params=approximator_params)

std = np.ones(2)
policy = DiagonalGaussianPolicy(mu=approximator, std=std)


# Agent
optimizer = AdaptiveOptimizer(0.1)
agent = GPOMDP(mdp.info, policy, optimizer, phi)

# Train
core = Core(agent, mdp)
print('Initial evaluation')
dataset_eval = core.evaluate(n_episodes=ep_per_run)
J = compute_J(dataset_eval, gamma=mdp.info.gamma)
print('J at start : ' + str(np.mean(J)))

for i in range(n_epochs):
    print('iteration', i)
    print('learn')
    core.learn(n_episodes=n_iterations * ep_per_run,
               n_episodes_per_fit=ep_per_run)
    print('evaluate')
    dataset_eval = core.evaluate(n_episodes=ep_per_run)
    J = compute_J(dataset_eval, gamma=mdp.info.gamma)
    print('J at iteration ' + str(i) + ': ' + str(np.mean(J)))

mdp.stop()

