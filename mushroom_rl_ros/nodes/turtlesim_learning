#!/usr/bin/env python3

import numpy as np

from mushroom_rl_ros.environments import TurtleSim

from mushroom_rl.core import Core, Logger
from mushroom_rl.algorithms.policy_search import GPOMDP
from mushroom_rl.approximators.parametric import LinearApproximator
from mushroom_rl.approximators.regressor import Regressor
from mushroom_rl.features.features import Features
from mushroom_rl.features.basis import GaussianRBF
from mushroom_rl.policy import DiagonalGaussianPolicy
from mushroom_rl.utils.optimizers import AdaptiveOptimizer
from mushroom_rl.utils.dataset import compute_J


def experiment(n_epochs, n_iterations, ep_per_run):
    logger = Logger('TurtleSim', results_dir=None)
    logger.strong_line()
    logger.info('Running TurtleSim experiment')

    # Environment
    mdp = TurtleSim()

    # Policy
    basis = GaussianRBF.generate([10, 10, 5], mdp.info.observation_space.low, mdp.info.observation_space.high)

    phi = Features(basis_list=basis)

    input_shape = (phi.size,)

    approximator_params = dict(input_dim=phi.size)
    approximator = Regressor(LinearApproximator, input_shape=input_shape,
                             output_shape=mdp.info.action_space.shape,
                             params=approximator_params)

    std = np.ones(2)
    policy = DiagonalGaussianPolicy(mu=approximator, std=std)


    # Agent
    optimizer = AdaptiveOptimizer(0.1)
    agent = GPOMDP(mdp.info, policy, optimizer, phi)

    logger.info('Experiment Algorithm: ' + agent.__class__.__name__)

    # Train
    core = Core(agent, mdp)

    dataset_eval = core.evaluate(n_episodes=ep_per_run)
    J = compute_J(dataset_eval, gamma=mdp.info.gamma)
    logger.epoch_info(0, J=np.mean(J))

    for i in range(n_epochs):
        core.learn(n_episodes=n_iterations * ep_per_run,
                   n_episodes_per_fit=ep_per_run)
        dataset_eval = core.evaluate(n_episodes=ep_per_run)
        J = compute_J(dataset_eval, gamma=mdp.info.gamma)
        logger.epoch_info(i+1, J=np.mean(J))

    mdp.stop()


if __name__ == '__main__':
    experiment(n_epochs=20, n_iterations=3, ep_per_run=10)