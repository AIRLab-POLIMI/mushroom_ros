#!/usr/bin/env python3

import numpy as np

from mushroom_rl_ros.environments import TurtlebotGazebo

from mushroom_rl.core import Core
from mushroom_rl.algorithms.policy_search import REINFORCE
from mushroom_rl.approximators.parametric import LinearApproximator
from mushroom_rl.approximators.regressor import Regressor
from mushroom_rl.features.features import Features
from mushroom_rl.features.tensors import GaussianRBFTensor
from mushroom_rl.policy import GaussianPolicy
from mushroom_rl.utils.optimizers import AdaptiveOptimizer
from mushroom_rl.utils.dataset import compute_J



# Learning parameters
n_runs = 4
n_iterations = 10
ep_per_run = 3

# Environment
mdp = TurtlebotGazebo()

# Policy
tensor_list = GaussianRBFTensor.generate([10, 10, 6],
                                         mdp.info.observation_space.low,
                                         mdp.info.observation_space.high)

phi = Features(tensor_list=tensor_list)


input_shape = (600,)

approximator = Regressor(LinearApproximator, input_shape=input_shape,
                         output_shape=mdp.info.action_space.shape)

sigma = np.eye(2)*1e-1
policy = GaussianPolicy(mu=approximator, sigma=sigma)


# Agent
optimizer = AdaptiveOptimizer(5)
agent = REINFORCE(mdp.info, policy, optimizer, phi)

# Train
core = Core(agent, mdp)
print('Initial evaluation')
dataset_eval = core.evaluate(n_episodes=ep_per_run)
J = compute_J(dataset_eval, gamma=mdp.info.gamma)
print('J at start : ' + str(np.mean(J)))

for i in range(n_runs):
    print('iteration', i)
    print('learn')
    core.learn(n_episodes=n_iterations * ep_per_run,
               n_episodes_per_fit=ep_per_run)
    print('evaluate')
    dataset_eval = core.evaluate(n_episodes=ep_per_run)
    J = compute_J(dataset_eval, gamma=mdp.info.gamma)
    print('J at iteration ' + str(i) + ': ' + str(np.mean(J)))
    
mdp.stop()

